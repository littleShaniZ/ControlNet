{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrqJTQqGswc2Ge+ZDPdWOZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/littleShaniZ/ControlNet/blob/SelectiveControlNet/BasicControlNetLineart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T54G8Y4C02dy"
      },
      "outputs": [],
      "source": [
        "# Basic ControlNet Lineart Inference (Minimal Setup)\n",
        "\n",
        "# --- ðŸ§© Cell 1: Install required packages ---\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q opencv-python transformers diffusers\n",
        "\n",
        "# --- ðŸ§© Cell 2: Clone ControlNet v1.1-nightly ---\n",
        "!git clone https://github.com/lllyasviel/ControlNet-v1-1-nightly.git\n",
        "%cd ControlNet-v1-1-nightly\n",
        "\n",
        "# --- ðŸ§© Cell 3: Download pretrained lineart model ---\n",
        "!mkdir -p models\n",
        "!wget -O models/control_sd15_lineart.pth https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_sd15_lineart.pth\n",
        "\n",
        "# --- ðŸ§© Cell 4: Import dependencies ---\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from cldm.model import create_model, load_state_dict\n",
        "from cldm.ddim_hacked import DDIMSampler\n",
        "from annotator.lineart import apply_lineart\n",
        "\n",
        "# --- ðŸ§© Cell 5: Load and preprocess image ---\n",
        "image_path = \"test_imgs/person_2.png\"\n",
        "input_image = Image.open(image_path).convert(\"RGB\").resize((512, 512))\n",
        "input_np = np.array(input_image)\n",
        "hint_np = apply_lineart(input_np)\n",
        "\n",
        "# --- ðŸ§© Cell 6: Setup model ---\n",
        "model = create_model('./configs/controlnet.yaml').cpu()\n",
        "model.load_state_dict(load_state_dict('./models/control_sd15_lineart.pth', location='cuda'))\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "sampler = DDIMSampler(model)\n",
        "\n",
        "# --- ðŸ§© Cell 7: Prompt setup ---\n",
        "prompt = \"a woman in futuristic cyberpunk style\"\n",
        "n_prompt = \"blurry, distorted, low quality\"\n",
        "\n",
        "# --- ðŸ§© Cell 8: Prepare conditioning input ---\n",
        "cond = torch.tensor(hint_np / 255.0).float()\n",
        "cond = cond[None, None, :, :].repeat(1, 3, 1, 1).cuda()\n",
        "\n",
        "# --- ðŸ§© Cell 9: Sampling ---\n",
        "ddim_steps = 30\n",
        "strength = 1.0\n",
        "guide_scale = 9.0\n",
        "eta = 0.0\n",
        "\n",
        "shape = (4, 64, 64)\n",
        "uc = model.get_learned_conditioning([n_prompt])\n",
        "c = model.get_learned_conditioning([prompt])\n",
        "cond_dict = {\"c_concat\": [cond], \"c_crossattn\": [c]}\n",
        "uc_dict = {\"c_concat\": [cond], \"c_crossattn\": [uc]}\n",
        "\n",
        "model.control_scales = [strength] * 13\n",
        "\n",
        "samples, _ = sampler.sample(\n",
        "    ddim_steps, batch_size=1, shape=shape, conditioning=cond_dict,\n",
        "    verbose=False, unconditional_guidance_scale=guide_scale,\n",
        "    unconditional_conditioning=uc_dict, eta=eta, x_T=None\n",
        ")\n",
        "\n",
        "# --- ðŸ§© Cell 10: Decode and display result ---\n",
        "from cldm.model import torch_to_numpy, autoencoder\n",
        "result = autoencoder.decode(samples[0].unsqueeze(0))\n",
        "result_image = Image.fromarray(torch_to_numpy(result))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Lineart Hint\")\n",
        "plt.imshow(hint_np, cmap='gray')\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Generated Output\")\n",
        "plt.imshow(result_image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    }
  ]
}